{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dictionary has: 29 tokens\n",
      "\n",
      "{'Gensim': 0, 'Python': 1, 'a': 2, 'algorithms.': 3, 'and': 4, 'as': 5, 'designed': 6, 'digital': 7, 'documents': 8, 'efficiently': 9, 'for': 10, 'free': 11, 'is': 12, 'learning': 13, 'library': 14, 'machine': 15, 'open-source': 16, 'painlessly': 17, 'possible.': 18, 'process': 19, 'raw,': 20, 'representing': 21, 'semantic': 22, 'texts': 23, 'to': 24, 'unstructured': 25, 'unsupervised': 26, 'using': 27, 'vectors,': 28}\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim import corpora\n",
    "\n",
    "text1 = [\"\"\"Gensim is a free open-source Python library for representing documents as semantic vectors,\n",
    "           as efficiently and painlessly as possible. Gensim is designed \n",
    "           to process raw, unstructured digital texts using unsupervised machine learning algorithms.\"\"\"]\n",
    "\n",
    "tokens1 = [[item for item in line.split()] for line in text1]\n",
    "g_dict1 = corpora.Dictionary(tokens1)\n",
    "\n",
    "print(\"The dictionary has: \" +str(len(g_dict1)) + \" tokens\\n\")\n",
    "print(g_dict1.token2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dictionary has: 57 tokens\n",
      "\n",
      "{'analyzing': 0, 'and': 1, 'branch': 2, 'consists': 3, 'data': 4, 'deriving': 5, 'efficient': 6, 'for': 7, 'from': 8, 'in': 9, 'information': 10, 'is': 11, 'manner': 12, 'nlp': 13, 'of': 14, 'processes': 15, 'science': 16, 'smart': 17, 'systematic': 18, 'text': 19, 'that': 20, 'the': 21, 'understanding': 22, 'analysis': 23, 'as': 24, 'automated': 25, 'automatic': 26, 'by': 27, 'can': 28, 'chunks': 29, 'components': 30, 'entity': 31, 'etc': 32, 'extraction': 33, 'its': 34, 'machine': 35, 'massive': 36, 'named': 37, 'numerous': 38, 'one': 39, 'organize': 40, 'perform': 41, 'problems': 42, 'range': 43, 'recognition': 44, 'relationship': 45, 'segmentation': 46, 'sentiment': 47, 'solve': 48, 'speech': 49, 'such': 50, 'summarization': 51, 'tasks': 52, 'topic': 53, 'translation': 54, 'utilizing': 55, 'wide': 56}\n"
     ]
    }
   ],
   "source": [
    "from gensim.utils import simple_preprocess\n",
    "from gensim import corpora\n",
    "\n",
    "text2 = open('sample_text.txt', encoding ='utf-8')\n",
    " \n",
    "tokens2 =[]\n",
    "for line in text2.read().split('.'):\n",
    "  tokens2.append(simple_preprocess(line, deacc = True))\n",
    "\n",
    "g_dict2 = corpora.Dictionary(tokens2)\n",
    "\n",
    "print(\"The dictionary has: \" +str(len(g_dict2)) + \" tokens\\n\")\n",
    "print(g_dict2.token2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'g_dict1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mg_dict1\u001b[49m\u001b[38;5;241m.\u001b[39madd_documents(tokens2)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe dictionary has: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mlen\u001b[39m(g_dict1)) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m tokens\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(g_dict1\u001b[38;5;241m.\u001b[39mtoken2id)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'g_dict1' is not defined"
     ]
    }
   ],
   "source": [
    "g_dict1.add_documents(tokens2)\n",
    "\n",
    "print(\"The dictionary has: \" +str(len(g_dict1)) + \" tokens\\n\")\n",
    "print(g_dict1.token2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokens1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m g_bow \u001b[38;5;241m=\u001b[39m[g_dict1\u001b[38;5;241m.\u001b[39mdoc2bow(token, allow_update \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtokens1\u001b[49m]\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBag of Words : \u001b[39m\u001b[38;5;124m\"\u001b[39m, g_bow)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tokens1' is not defined"
     ]
    }
   ],
   "source": [
    "g_bow =[g_dict1.doc2bow(token, allow_update = True) for token in tokens1]\n",
    "print(\"Bag of Words : \", g_bow)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
